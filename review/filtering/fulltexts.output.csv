id,databases,title,year,authors,publication_type,published_in,num_references,num_citations,abstract,keywords,pdf,url
1,"ACM, Google Scholar",Measuring article quality in wikipedia: models and evaluation,2007,Meiqun Hu; Ee-Peng Lim; Aixin Sun; Hady W. Lauw; Ba-Quy Vuong,Conference,"International Conference on Information and Knowledge Management, pp. 243-252",31,282,"Wikipedia has grown to be the world largest and busiest free encyclopedia, in which articles are collaboratively written and maintained by volunteers online. Despite its success as a means of knowledge sharing and collaboration, the public has never stopped criticizing the quality of Wikipedia articles edited by non-experts and inexperienced contributors. In this paper, we investigate the problem of assessing the quality of articles in collaborative authoring of Wikipedia. We propose three article quality measurement models that make use of the interaction data between articles and their contributors derived from the article edit history. Our Basic model is designed based on the mutual dependency between article quality and their author authority. The PeerReview model introduces the review behavior into measuring article quality. Finally, our ProbReview models extend PeerReview with partial reviewership of contributors as they edit various portions of the articles. We conduct experiments on a set of well-labeled Wikipedia articles to evaluate the effectiveness of our quality measurement models in resembling human judgement.",,https://dl.acm.org/doi/pdf/10.1145/1321440.1321476,https://dl.acm.org/doi/10.1145/1321440.1321476
4,"ACM, Google Scholar",Size matters: word count as a measure of quality on wikipedia,2008,J. Blumenstock,Conference,"The Web Conference, pp. 1095-1096",6,315,"Wikipedia, ""the free encyclopedia"", now contains over two million English articles, and is widely regarded as a high-quality, authoritative encyclopedia. Some Wikipedia articles, however, are of questionable quality, and it is not always apparent to the visitor which articles are good and which are bad. We propose a simple metric -- word count -- for measuring article quality. In spite of its striking simplicity, we show that this metric significantly outperforms the more complex methods described in related work.",,https://dl.acm.org/doi/pdf/10.1145/1367497.1367673,https://dl.acm.org/doi/10.1145/1367497.1367673
8,"ACM, Google Scholar",On measuring the quality of Wikipedia articles,2010,Gabriel De la Calzada; Alex Dekhtyar,Conference,"Workshop on Information Credibility on the Web, pp. 11-18",51,65,"This paper discusses an approach to modeling and measuring information quality of Wikipedia articles. The approach is based on the idea that the quality of Wikipedia articles with distinctly different profiles needs to be measured using different information quality models. We report on our initial study, which involved two categories of Wikipedia articles: ""stabilized"" (those, whose content has not undergone major changes for a significant period of time) and ""controversial"" (the articles, which have undergone vandalism, revert wars, or whose content is subject to internal discussions between Wikipedia editors). We present simple information quality models and compare their performance on a subset of Wikipedia articles with the information quality evaluations provided by human users. Our experiment shows, that using special-purpose models for information quality captures user sentiment about Wikipedia articles better than using a single model for both categories of articles.",,https://dl.acm.org/doi/pdf/10.1145/1772938.1772943,https://dl.acm.org/doi/10.1145/1772938.1772943
10,"ACM, Google Scholar",Assessing the quality of Wikipedia articles with lifecycle based metrics,2009,T. Wöhner; Ralf Peters,Journal,N/A,27,126,"The main feature of the free online-encyclopedia Wikipedia is the wiki-tool, which allows viewers to edit the articles directly in the web browser. As a weakness of this openness for example the possibility of manipulation and vandalism cannot be ruled out, so that the quality of any given Wikipedia article is not guaranteed. Hence the automatic quality assessment has been becoming a high active research field. In this paper we offer new metrics for an efficient quality measurement. The metrics are based on the lifecycles of low and high quality articles, which refer to the changes of the persistent and transient contributions throughout the entire life span.",,https://dl.acm.org/doi/pdf/10.1145/1641309.1641333,https://dl.acm.org/doi/10.1145/1641309.1641333
11,"ACM, Google Scholar",Statistical measure of quality in Wikipedia,2010,S. Javanmardi; C. Lopes,Conference,N/A,26,51,"Wikipedia is commonly viewed as the main online encyclopedia. Its content quality, however, has often been questioned due to the open nature of its editing model. A high--quality contribution by an expert may be followed by a low-quality contribution made by an amateur or a vandal; therefore the quality of each article may fluctuate over time as it goes through iterations of edits by different users. With the increasing use of Wikipedia, the need for a reliable assessment of the quality of the content is also rising. In this study, we model the evolution of content quality in Wikipedia articles in order to estimate the fraction of time during which articles retain high-quality status. To evaluate the model, we assess the quality of Wikipedia's featured and non-featured articles. We show how the model reproduces consistent results with what is expected. As a case study, we use the model in a CalSWIM mashup the content of which is taken from both highly reliable sources and Wikipedia, which may be less so. Integrating CalSWIM with a trust management system enables it to use not only recency but also quality as its criteria, and thus filter out vandalized or poor-quality content.",,https://dl.acm.org/doi/pdf/10.1145/1964858.1964876,https://dl.acm.org/doi/10.1145/1964858.1964876
13,"ACM, Google Scholar",Tell me more: an actionable quality model for Wikipedia,2013,Morten Warncke-Wang; D. Cosley; J. Riedl,Conference,Proceedings of the 9th International Symposium on Open Collaboration,41,110,"In this paper we address the problem of developing actionable quality models for Wikipedia, models whose features directly suggest strategies for improving the quality of a given article. We first survey the literature in order to understand the notion of article quality in the context of Wikipedia and existing approaches to automatically assess article quality. We then develop classification models with varying combinations of more or less actionable features, and find that a model that only contains clearly actionable features delivers solid performance. Lastly we discuss the implications of these results in terms of how they can help improve the quality of articles across Wikipedia.",,https://dl.acm.org/doi/pdf/10.1145/2491055.2491063,https://dl.acm.org/doi/10.1145/2491055.2491063
14,"ACM, Google Scholar, Web of Science",Automatic quality assessment of content created collaboratively by web communities: a case study of wikipedia,2009,D. H. Dalip; Marcos André Gonçalves; Marco Cristo; P. Calado,Conference,"ACM/IEEE Joint Conference on Digital Libraries, pp. 295-304",31,125,"The old dream of a universal repository containing all the human knowledge and culture is becoming possible through the Internet and the Web. Moreover, this is happening with the direct collaborative, participation of people. Wikipedia is a great example. It is an enormous repository of information with free access and edition, created by the community in a collaborative manner. However, this large amount of information, made available democratically and virtually without any control, raises questions about its relative quality. In this work we explore a significant number of quality indicators, some of them proposed by us and used here for the first time, and study their capability to assess the quality of Wikipedia articles. Furthermore, we explore machine learning techniques to combine these quality indicators into one single assessment judgment. Through experiments, we show that the most important quality indicators are the easiest ones to extract, namely, textual features related to length, structure and style. We were also able to determine which indicators did not contribute significantly to the quality assessment. These were, coincidentally, the most complex features, such as those based on link analysis. Finally, we compare our combination method with state-of-the-art solution and show significant improvements in terms of effective quality prediction.",,https://dl.acm.org/doi/pdf/10.1145/1555400.1555449,https://dl.acm.org/doi/10.1145/1555400.1555449
15,Google Scholar,Learning to Predict the Quality of Contributions to Wikipedia,2008,Gregory Druck; G. Miklau; A. McCallum,Journal,N/A,11,52,"Although some have argued that Wikipedia’s open edit policy is one of the primary reasons for its success, it also raises concerns about quality — vandalism, bias, and errors can be problems. Despite these challenges, Wikipedia articles are often (perhaps surprisingly) of high quality, which many attribute to both the dedicatedWikipedia community and “good Samaritan” users. As Wikipedia continues to grow, however, it becomes more difficult for these users to keep up with the increasing number of articles and edits. This motivates the development of tools to assist users in creating and maintaining quality. In this paper, we propose metrics that quantify the quality of contributions to Wikipedia through implicit feedback from the community. We then learn discriminative probabilistic models that predict the quality of a new edit using features of the changes made, the author of the edit, and the article being edited. Through estimating parameters for these models, we also gain an understanding of factors that influence quality. We advocate using edit quality predictions and information gleaned from model analysis not to place restrictions on editing, but to instead alert users to potential quality problems, and to facilitate the development of additional incentives for contributors. We evaluate the edit quality prediction models on the Spanish Wikipedia. Experiments demonstrate that the models perform better when given access to content-based features of the edit, rather than only features of contributing user. This suggests that a user-based solution to the Wikipedia quality problem may not be sufficient. Introduction and Motivation Collaborative content generation systems such as Wikipedia are promising because they facilitate the integration of information from many disparate sources. Wikipedia is remarkable because anyone can edit an article. Some argue that this open edit policy is one of the key reasons for its success (Roth 2007; Riehle 2006). However, this openness does raise concerns about quality — vandalism, bias, and errors can be problems (Denning et al. 2005; Riehle 2006; Kittur et al. 2007). Despite the challenges associated with an open edit policy, Wikipedia articles are often of high quality (Giles 2005). Many suggest that this is a result of dedicated users that make many edits, monitor articles for changes, and engage Copyright c © 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. in debates on article discussion pages. These users are sometimes referred to as “zealots” (Anthony, Smith, and Williamson 2007), and studies claim that they are motivated by a system of peer recognition that bears resemblance to the academic community (Forte and Bruckman 2005). However, the contributions of “good Samaritan” users, who edit articles but have no desire to participate in the community, cannot not be underestimated (Anthony, Smith, and Williamson 2007). As Wikipedia continues to grow, however, it becomes more difficult for these users to keep up with the increasing number of articles and edits. Zealots comprise a relatively small portion of all Wikipedia users. Good Samaritan users are not likely to seek out errors, but instead rely on stumbling upon them. It is interesting to consider whether aiding users in detecting and focusing effort on quality problems could improve Wikipedia. In this paper, we examine the problem of estimating the quality of a new edit. Immediately, we face the problem of defining edit quality. It has been argued that there is no general definition of information quality, and hence quality must be defined using empirical observations of community interactions (Stvilia et al. 2008). Therefore, we define quality using implicit feedback from the Wikipedia community itself. That is, by observing the community’s response to a particular edit, we can estimate the edit’s quality. The quality metrics we propose are based on the assumption that edits to an article that are retained in subsequent versions of the article are of high quality, whereas edits that are quickly removed are of low quality. We use these community-defined measures of edit quality to learn statistical models that can predict the quality of a new edit. Quality is predicted using features of the edit itself, the author of the edit, and the article being edited. Through learning to predict quality, we also learn about factors that influence quality. Specifically, we provide analysis of model parameters to determine which features are the most useful for predicting quality. We advocate using edit quality predictions and information gleaned from model analysis not to place restrictions on editing, but to assist users in improving quality. That is, we aim to maintain a low barrier to participation, as those users not interested in the Wikipedia community can still be valuable contributors (Anthony, Smith, and Williamson 2007). Restrictions might also discourage new users, and drive away users who were drawn to the idea of a openly editable encyclopedia. Consequently, we suggest that the quality models be used to help users focus on predicted quality problems or to encourage participation. We evaluate the edit quality prediction models and provide analysis using the Spanish Wikipedia. Experiments demonstrate that the models attain better results when given access to content-based features, in addition to features of the contributing user. This suggests that a user-based solution to the Wikipedia quality problem may not be sufficient. Although we focus on Wikipedia in this paper, we think of this as an instance of a new problem: automatically predicting the quality of contributions in a collaborative environment.",,https://www.aaai.org/Papers/Workshops/2008/WS-08-15/WS08-15-002.pdf,https://www.aaai.org/Library/Workshops/2008/ws08-15-002.php
16,"Google Scholar, Web of Science",Measuring Quality of Collaboratively Edited Documents: The Case of Wikipedia,2016,Quang-Vinh Dang; C. Ignat,Conference,"2016 IEEE 2nd International Conference on Collaboration and Internet Computing (CIC), pp. 266-275",69,32,"Wikipedia is a great example of large scale collaboration, where people from all over the world together build the largest and maybe the most important human knowledge repository in the history. However, a number of studies showed that the quality of Wikipedia articles is not equally distributed. While many articles are of good quality, many others need to be improved. Assessing the quality of Wikipedia articles is very important for guiding readers towards articles of high quality and suggesting authors and reviewers which articles need to be improved. Due to the huge size of Wikipedia, an effective automatic assessment method to measure Wikipedia articles quality is needed. In this paper, we present an automatic assessment method of Wikipedia articles quality by analyzing their content in terms of their format features and readability scores. Our results show improvements both in terms of accuracy and information gain compared with other existing approaches.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7809715,https://ieeexplore.ieee.org/document/7809715
17,"ACM, Google Scholar, Web of Science",Predicting quality flaws in user-generated content: the case of wikipedia,2012,Maik Anderka; Benno Stein; Nedim Lipka,Conference,"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 981-990",159,96,"The detection and improvement of low-quality information is a key concern in Web applications that are based on user-generated content; a popular example is the online encyclopedia Wikipedia. Existing research on quality assessment of user-generated content deals with the classification as to whether the content is high-quality or low-quality. This paper goes one step further: it targets the prediction of quality flaws, this way providing specific indications in which respects low-quality content needs improvement. The prediction is based on user-defined cleanup tags, which are commonly used in many Web applications to tag content that has some shortcomings. We apply this approach to the English Wikipedia, which is the largest and most popular user-generated knowledge source on the Web. We present an automatic mining approach to identify the existing cleanup tags, which provides us with a training corpus of labeled Wikipedia articles. We argue that common binary or multiclass classification approaches are ineffective for the prediction of quality flaws and hence cast quality flaw prediction as a one-class classification problem. We develop a quality flaw model and employ a dedicated machine learning approach to predict Wikipedia's most important quality flaws. Since in the Wikipedia setting the acquisition of significant test data is intricate, we analyze the effects of a biased sample selection. In this regard we illustrate the classifier effectiveness as a function of the flaw distribution in order to cope with the unknown (real-world) flaw-specific class imbalances. The flaw prediction performance is evaluated with 10,000 Wikipedia articles that have been tagged with the ten most frequent quality flaws: provided test data with little noise, four flaws can be detected with a precision close to 1.",,https://dl.acm.org/doi/pdf/10.1145/2348283.2348413,https://dl.acm.org/doi/10.1145/2348283.2348413
18,"Google Scholar, Web of Science",Quality and Importance of Wikipedia Articles in Different Languages,2016,Włodzimierz Lewoniewski; Krzysztof Węcel; W. Abramowicz,Conference,"International Conference on Information and Software Technologies, pp. 613-624",23,26,"This article aims to analyse the importance of the Wikipedia articles in different languages (English, French, Russian, Polish) and the impact of the importance on the quality of articles. Based on the analysis of literature and our own experience we collected measures related to articles, specifying various aspects of quality that will be used to build the models of articles’ importance. For each language version, the influential parameters are selected that may allow automatic assessment of the validity of the article. Links between articles in different languages offer opportunities in terms of comparison and verification of the quality of information provided by various Wikipedia communities. Therefore, the model can be used not only for a relative assessment of the content of the whole article, but also for a relative assessment of the quality of data contained in their structural parts, the so-called infoboxes.",,https://link.springer.com/content/pdf/10.1007/978-3-319-46254-7_50,https://link.springer.com/chapter/10.1007/978-3-319-46254-7_50
19,"ACM, Google Scholar","A jury of your peers: quality, experience and ownership in Wikipedia",2009,Aaron L Halfaker; A. Kittur; R. Kraut; J. Riedl,Journal,N/A,24,104,"Wikipedia is a highly successful example of what mass collaboration in an informal peer review system can accomplish. In this paper, we examine the role that the quality of the contributions, the experience of the contributors and the ownership of the content play in the decisions over which contributions become part of Wikipedia and which ones are rejected by the community. We introduce and justify a versatile metric for automatically measuring the quality of a contribution. We find little evidence that experience helps contributors avoid rejection. In fact, as they gain experience, contributors are even more likely to have their work rejected. We also find strong evidence of ownership behaviors in practice despite the fact that ownership of content is discouraged within Wikipedia.",,https://dl.acm.org/doi/pdf/10.1145/1641309.1641332,https://dl.acm.org/doi/10.1145/1641309.1641332
20,Google Scholar,Automatically Assessing Wikipedia Article Quality by Exploiting Article-Editor Networks,2015,Xinyi Li; Jintao Tang; Ting Wang; Zhunchen Luo; M. de Rijke,Conference,"European Conference on Information Retrieval, pp. 574-580",16,37,"We consider the problem of automatically assessing Wikipedia article quality. We develop several models to rank articles by using the editing relations between articles and editors. First, we create a basic model by modeling the article-editor network. Then we design measures of an editor’s contribution and build weighted models that improve the ranking performance. Finally, we use a combination of featured article information and the weighted models to obtain the best performance. We find that using manual evaluation to assist automatic evaluation is a viable solution for the article quality assessment task on Wikipedia",,https://link.springer.com/content/pdf/10.1007/978-3-319-16354-3_64,https://link.springer.com/chapter/10.1007/978-3-319-16354-3_64
23,"ACM, Google Scholar",An end-to-end learning solution for assessing the quality of Wikipedia articles,2017,Quang-Vinh Dang; C. Ignat,Conference,Proceedings of the 13th International Symposium on Open Collaboration,60,28,"Wikipedia is considered as the largest knowledge repository in the history of humanity and plays a crucial role in modern daily life. Assigning the correct quality class to Wikipedia articles is an important task in order to provide guidance for both authors and readers of Wikipedia. The manual review cannot cope with the editing speed of Wikipedia. An automatic classification is required to classify the quality of Wikipedia articles. Most existing approaches rely on traditional machine learning with manual feature engineering, which requires a lot of expertise and effort. Furthermore, it is known that there is no general perfect feature set because information leak always occurs in feature extraction phase. Also, for each language of Wikipedia, a new feature set is required. In this paper, we present an approach relying on deep learning for quality classification of Wikipedia articles. Our solution relies on Recurrent Neural Networks (RNN) which is an end-to-end learning technique that eliminates disadvantages of feature engineering. Our approach learns directly from raw data without human intervention and is language-neutral. Experimental results on English, French and Russian Wikipedia datasets show that our approach outperforms state-of-the-art solutions.",,https://dl.acm.org/doi/pdf/10.1145/3125433.3125448,https://dl.acm.org/doi/10.1145/3125433.3125448
24,"ACM, Google Scholar, Web of Science",Quality assessment of Wikipedia articles without feature engineering,2016,Quang-Vinh Dang; C. Ignat,Conference,"2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL), pp. 27-30",25,54,"As Wikipedia became the largest human knowledge repository, quality measurement of its articles received a lot of attention during the last decade. Most research efforts focused on classification of Wikipedia articles quality by using a different feature set. However, so far, no “golden feature set” was proposed. In this paper, we present a novel approach for classifying Wikipedia articles by analysing their content rather than by considering a feature set. Our approach uses recent techniques in natural language processing and deep learning, and achieved a comparable result with the state-of-the-art.",,https://dl.acm.org/doi/pdf/10.1145/2910896.2910917,https://dl.acm.org/doi/10.1145/2910896.2910917
26,"ACM, Google Scholar, Web of Science",Assessing the quality of information on wikipedia: A deep‐learning approach,2020,Ping Wang; Xiaodan Li,Journal,"Journal of the Association for Information Science and Technology, 71",73,18,"Currently, web document repositories have been collaboratively created and edited. One of these repositories, Wikipedia, is facing an important problem: assessing the quality of Wikipedia. Existing approaches exploit techniques such as statistical models or machine leaning algorithms to assess Wikipedia article quality. However, existing models do not provide satisfactory results. Furthermore, these models fail to adopt a comprehensive feature framework. In this article, we conduct an extensive survey of previous studies and summarize a comprehensive feature framework, including text statistics, writing style, readability, article structure, network, and editing history. Selected state‐of‐the‐art deep‐learning models, including the convolutional neural network (CNN), deep neural network (DNN), long short‐term memory (LSTMs) network, CNN‐LSTMs, bidirectional LSTMs, and stacked LSTMs, are applied to assess the quality of Wikipedia. A detailed comparison of deep‐learning models is conducted with regard to different aspects: classification performance and training performance. We include an importance analysis of different features and feature sets to determine which features or feature sets are most effective in distinguishing Wikipedia article quality. This extensive experiment validates the effectiveness of the proposed model.",,https://www.researchgate.net/publication/332294515_Assessing_the_quality_of_information_on_wikipedia_A_deep-learning_approach,https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.24210
30,Google Scholar,Measuring article quality in Wikipedia: Lexical clue model,2011,Yanxiang Xu; Tiejian Luo,Conference,"2011 3rd Symposium on Web Society, pp. 141-146",16,33,"Wikipedia is the most entry-abundant on-line encyclopedia. Some studies published by Nature proved that the scientific entries in Wikipedia are of good quality comparable to those in the Encyclopedia Britannica which are mainly maintained by experts. But the manual partition of the articles in Wikipedia from a WikiProject implies that high-quality articles are usually reached grade by grade via being repeatedly revised. So many work address to automatically measuring the article quality in Wikipedia based on some assumption of the relationship between the article quality and contributors' reputations, view behaviors, article status, inter-article link, or so on. In this paper, a lexical clue based measuring method is proposed to assess article quality in Wikipedia. The method is inspired the idea that the good articles have more regular statistic features on lexical usage than the primary ones due to the more revise by more people. We select 8 lexical features derived from the statistic on word usages in articles as the factors that can reflect article quality in Wikipedia. A decision tree is trained based on the lexical clue model. Using the decision tree, our experiments on a well-labeled collection of 200 Wikipedia articles shows that our method has more than 83% precise and recall.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6101286,https://ieeexplore.ieee.org/document/6101286
31,Google Scholar,A Hybrid Model for Quality Assessment of Wikipedia Articles,2017,Aili Shen; Jianzhong Qi; Timothy Baldwin,Conference,"Australasian Language Technology Association Workshop, pp. 43-52",44,26,"The task of document quality assessment is a highly complex one, which draws on analysis of aspects including linguistic content, document structure, fact correctness, and community norms. We explore the task in the context of a Wikipedia article assessment task, and propose a hybrid approach combining deep learning with features proposed in the literature. Our method achieves 6.5% higher accuracy than the state of the art in predicting the quality classes of English Wikipedia articles over a novel dataset of around 60k Wikipedia articles. We also discuss limitations with this task setup, and possible directions for establishing more robust document quality assessment evaluations.",,https://aclanthology.org/U17-1005.pdf,https://aclanthology.org/U17-1005/
32,"ACM, Google Scholar, Web of Science",Measuring article quality in Wikipedia using the collaboration network,2015,Baptiste de La Robertie; Y. Pitarch; O. Teste,Conference,"2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), pp. 464-471",17,32,"Collaboratively edited articles such as in Wikipedia suffer from well-identified problems regarding their quality, e.g., information accuracy, reputability of third-party sources, vandalism. Due to the huge number of articles and the intensive edit rate, the manual evaluation of article content quality is inconceivable. In this paper, we tackle the problem of automatically establishing the quality of Wikipedia articles. Evidences are shown to consider the interactions between authors and articles to assess the quality score. Collaborations between authors and reviewers are also considered to reinforce the discriminative process. This work gives a generic formulation of the Mutual Reinforcement principle held between articles quality and authors authority and take explicitly advantage of the co-edits graph generated by individuals. Experiments conducted on a set of representative data from Wikipedia show the effectiveness of our approach.",,https://dl.acm.org/doi/pdf/10.1145/2808797.2808895,https://dl.acm.org/doi/10.1145/2808797.2808895
33,"ACM, Google Scholar, Web of Science",QuWi: quality control in Wikipedia,2009,Alberto Cusinato; V. D. Mea; F. Salvatore; S. Mizzaro,Conference,"Workshop on Information Credibility on the Web, pp. 27-34",19,24,"We propose and evaluate QuWi (Quality in Wikipedia), a framework for quality control in Wikipedia. We build upon a previous proposal by Mizzaro [11], who proposed a method for substituting and/or complementing peer review in scholarly publishing. Since articles in Wikipedia are never finished, and their authors change continuously, we define a modified algorithm that takes into account the different domain, with particular attention to the fact that authors contribute identifiable pieces of information that can be further modified by other authors. The algorithm assigns quality scores to articles and contributors. The scores assigned to articles can be used, e.g., to let the reader understand how reliable are the articles he or she is looking at, or to help contributors in identifying low quality articles to be enhanced. The scores assigned to users measure the average quality of their contributions to Wikipedia and can be used, e.g., for conflict resolution policies based on the quality of involved users. Our proposed algorithm is experimentally evaluated by analyzing the obtained quality scores on articles for deletion and featured articles, also on six temporal Wikipedia snapshots. Preliminary results demonstrate that the proposed algorithm seems to appropriately identify high and low quality articles, and that high quality authors produce more long-lived contributions than low quality authors.",,https://dl.acm.org/doi/pdf/10.1145/1526993.1527001,https://dl.acm.org/doi/10.1145/1526993.1527001
35,"ACM, Google Scholar",Towards automatic quality assurance in Wikipedia,2011,Maik Anderka; Benno Stein; Nedim Lipka,Conference,Proceedings of the 20th international conference companion on World wide web,13,28,"Featured articles in Wikipedia stand for high information quality, and it has been found interesting to researchers to analyze whether and how they can be distinguished from ""ordinary"" articles. Here we point out that article discrimination falls far short of writer support or automatic quality assurance: Featured articles are not identified, but are made. Following this motto we compile a comprehensive list of information quality flaws in Wikipedia, model them according to the latest state of the art, and devise one-class classification technology for their identification.",,https://dl.acm.org/doi/pdf/10.1145/1963192.1963196,https://dl.acm.org/doi/10.1145/1963192.1963196
36,"ACM, Google Scholar, Web of Science",What makes a good biography?: multidimensional quality analysis based on wikipedia article feedback data,2014,Lucie Flekova; Oliver Ferschke; Iryna Gurevych,Conference,Proceedings of the 23rd international conference on World wide web,47,25,"With more than 22 million articles, the largest collaborative knowledge resource never sleeps, experiencing several article edits every second. Over one fifth of these articles describes individual people, the majority of which are still alive. Such articles are, by their nature, prone to corruption and vandalism. Manual quality assurance by experts can barely cope with this massive amount of data. Can it be effectively replaced by feedback from the crowd? Can we provide meaningful support for quality assurance with automated text processing techniques? Which properties of the articles should then play a key role in the machine learning algorithms and why? In this paper, we study the user-perceived quality of Wikipedia articles based on a novel Wikipedia user feedback dataset. In contrast to previous work on quality assessment which mostly relied on judgements of active Wikipedia authors, we analyze ratings of ordinary Wikipedia users along four quality dimensions (Complete, Well written, Trustworthy and Objective). We first present an empirical analysis of the novel dataset with over 36 million Wikipedia article ratings. We then select a subset of biographical articles and perform classification experiments to predict their quality ratings along each of the dimensions, exploring multiple linguistic, surface and network properties of the rated articles. Additionally, we study the classification performance and differences for the biographies of living and dead people as well as those for men and women. We demonstrate the effectiveness of our approach by the F-scores of 0.94, 0.89, 0.73, and 0.73 for the dimensions Complete, Well written, Trustworthy, and Objective. Based on the results, we believe that the quality assessment of big textual data can be effectively supported by current text classification and language processing tools.",,https://dl.acm.org/doi/pdf/10.1145/2566486.2567972,https://dl.acm.org/doi/10.1145/2566486.2567972
38,"Google Scholar, Web of Science",NwQM: A Neural Quality Assessment Framework for Wikipedia,2020,Bhanu Prakash Reddy Guda; Sasi Bhusan; Soumya Sarkar; Animesh Mukherjee,Conference,"Conference on Empirical Methods in Natural Language Processing, pp. 8396-8406",40,5,"Millions of people irrespective of socioeconomic and demographic backgrounds, depend on Wikipedia articles everyday for keeping themselves informed regarding popular as well as obscure topics. Articles have been categorized by editors into several quality classes, which indicate their reliability as encyclopedic content. This manual designation is an onerous task because it necessitates profound knowledge about encyclopedic language, as well navigating circuitous set of wiki guidelines. In this paper we propose Neural wikipedia QualityMonitor (NwQM), a novel deep learning model which accumulates signals from several key information sources such as article text, meta data and images to obtain improved Wikipedia article representation. We present comparison of our approach against a plethora of available solutions and show 8% improvement over state-of-the-art approaches with detailed ablation studies.",,https://aclanthology.org/2020.emnlp-main.674.pdf,https://aclanthology.org/2020.emnlp-main.674/
41,"Google Scholar, Web of Science",History-Based Article Quality Assessment on Wikipedia,2018,Shiyue Zhang; Zheng Hu; Chunhong Zhang; K. Yu,Conference,"2018 IEEE International Conference on Big Data and Smart Computing (BigComp), pp. 1-8",30,12,"Wikipedia is widely considered as the biggest encyclopedia on Internet. Quality assessment of articles on Wikipedia has been studied for years. Conventional methods addressed this task by feature engineering and statistical machine learning algorithms. However, manually defined features are difficult to represent the long edit history of an article. Recently, researchers proposed an end-to-end neural model which used a Recurrent Neural Network(RNN) to learn the representation automatically. Although RNN showed its power in modeling edit history, the end-to-end method is time and resource consuming. In this paper, we propose a new history-based method to represent an article. We also take advantage of an RNN to handle the long edit history, but we do not abandon feature engineering. We still represent each revision of an article by manually defined features. This combination of deep neural model and feature engineering enables our model to be both simple and effective. Experiments demonstrate our model has better or comparable performance than previous works, and has the potential to work as a real-time service. Plus, we extend our model to do quality prediction.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8367090,https://ieeexplore.ieee.org/document/8367090
43,Google Scholar,FlawFinder: A Modular System for Predicting Quality Flaws in Wikipedia,2012,Oliver Ferschke; Iryna Gurevych; M. Rittberger,Conference,"Conference and Labs of the Evaluation Forum, ",30,30,"With over 23 million articles in 285 languages, Wikipedia is the largest free knowledge base on the web. Due to its open nature, everybody is allowed to access and edit the contents of this huge encyclopedia. As a downside of this open access policy, quality assessment of the content becomes a critical issue and is hardly manageable without computational assistance. In this paper, we present FlawFinder, a modular system for automatically predicting quality flaws in unseen Wikipedia articles. It competed in the inaugural edition of the Quality Flaw Prediction Task at the PAN Challenge 2012 and achieved the best precision of all systems and the second place in terms of recall and F1-score.",,https://ceur-ws.org/Vol-1178/CLEF2012wn-PAN-FerschkeEt2012.pdf,https://www.researchgate.net/publication/235982155_FlawFinder_A_Modular_System_for_Predicting_Quality_Flaws_in_Wikipedia
46,"Google Scholar, Web of Science",Relative Quality and Popularity Evaluation of Multilingual Wikipedia Articles,2017,Włodzimierz Lewoniewski; Krzysztof Węcel; W. Abramowicz,Journal,"Informatics, 4, pp. 43",27,32,"Despite the fact that Wikipedia is often criticized for its poor quality, it continues to be one of the most popular knowledge bases in the world. Articles in this free encyclopedia on various topics can be created and edited in about 300 different language versions independently. Our research has showed that in language sensitive topics, the quality of information can be relatively better in the relevant language versions. However, in most cases, it is difficult for the Wikipedia readers to determine the language affiliation of the described subject. Additionally, each language edition of Wikipedia can have own rules in the manual assessing of the content’s quality. There are also differences in grading schemes between language versions: some use a 6–8 grade system to assess articles, and some are limited to 2–3. This makes automatic quality comparison of articles between various languages a challenging task, particularly if we take into account a large number of unassessed articles; some of the Wikipedia language editions have over 99% of articles without a quality grade. The paper presents the results of a relative quality and popularity assessment of over 28 million articles in 44 selected language versions. Comparative analysis of the quality and the popularity of articles in popular topics was also conducted. Additionally, the correlation between quality and popularity of Wikipedia articles of selected topics in various languages was investigated. The proposed method allows us to find articles with information of better quality that can be used to automatically enrich other language editions of Wikipedia.",,https://pdfs.semanticscholar.org/a37c/5e68f712724157a4a6824f58a2425a830168.pdf,https://www.mdpi.com/2227-9709/4/4/43
48,"Google Scholar, Web of Science",A hybrid approach to classifying Wikipedia article quality flaws with feature fusion framework,2021,Ping Wang; Muyan Li; Xiaodan Li; Heshen Zhou; Jingrui Hou,Journal,"Expert Syst. Appl., 181, pp. 115089",30,6,"Article quality has always been a major concern for Wikipedia. To improve article quality, it is critical to first identify defects. Thus, flaw classification has attracted considerable attention. To achieve this, several machine-learning-based approaches are available, including deep learning models based on either manually constructed or autoextracted features. However, adopting only features of either single type may not ensure a comprehensive description of articles. To improve flaw classification, we propose a feature fusion framework combining both handcrafted and autoextracted features. In this research, we first use a rule-based method from a previously proposed framework to extract handcrafted features. Additionally, we obtain autoextracted features using Bidirectional Encoder Representations from Transformers (BERT) and various deep learning models, including bidirectional long short-term memory (Bi LSTM), bidirectional gated recurrent unit (Bi GRU), bidirectional recurrent neural network (Bi RNN), and multihead self-attention models. Finally, the handcrafted features are standardized and concatenated with the autoextracted features. Then, the concatenated features are fed into a feedforward neural network for classification. A detailed comparison of different classifiers is conducted. We compare 12 different classifiers in terms of training performance, classification performance, and model training time. The experiments show that the proposed feature fusion framework can notably improve the effectiveness of quality flaw classification for Wikipedia articles. In particular, a Bi GRU model based on the proposed framework achieves excellent classification accuracy.",,https://reader.elsevier.com/reader/sd/pii/S0957417421005303?token=5388C4415793DA7AF64CBE513CD8B789A104B546D63754CE10326DECA64378FAADD906AE25B606164B3F69EC4FA003F6&originRegion=eu-west-1&originCreation=20230130110039,https://www.sciencedirect.com/science/article/pii/S0957417421005303?via%3Dihub
58,"ACM, Google Scholar",On improving wikipedia search using article quality,2007,Meiqun Hu; Ee-Peng Lim; Aixin Sun; Hady W. Lauw; Ba-Quy Vuong,Conference,"ACM International Workshop on Web Information and Data Management, pp. 145-152",25,19,"Wikipedia is presently the largest free-and-open online encyclopedia collaboratively edited and maintained by volunteers. While Wikipedia offers full-text search to its users, the accuracy of its relevance-based search can be compromised by poor quality articles edited by non-experts and inexperienced contributors. In this paper, we propose a framework that re-ranks Wikipedia search results considering article quality. We develop two quality measurement models, namely Basic and PeerReview, to derive article quality based on co-authoring data gathered from articles' edit history. Compared with Wikipedia's full-text search engine, Google and Wikiseek, our experimental results showed that (i) quality-only ranking produced by PeerReview gives comparable performance to that of Wikipedia and Wikiseek; (ii) PeerReview combined with relevance ranking outperforms Wikipedia's full-text search significantly, delivering search accuracy comparable to Google.",,https://dl.acm.org/doi/pdf/10.1145/1316902.1316926,https://dl.acm.org/doi/10.1145/1316902.1316926
60,"ACM, Google Scholar",Mutual evaluation of editors and texts for assessing quality of Wikipedia articles,2012,Yumiko Suzuki; M. Yoshikawa,Conference,N/A,26,20,"In this paper, we propose a method to identify good quality Wikipedia articles by mutually evaluating editors and texts. A major approach for assessing article quality is a text survival ratio based approach. In this approach, when a text survives beyond multiple edits, the text is assessed as good quality. This approach assumes that poor quality texts are deleted by editors with high possibility. However, many vandals delete good quality texts frequently, then the survival ratios of good quality texts are improperly decreased by vandals. As a result, many good quality texts are unfairly assessed as poor quality. In our method, we consider editor quality for calculating text quality, and decrease the impacts on text qualities by the vandals who has low quality. Using this improvement, the accuracy of the text quality should be improved. However, an inherent problem of this idea is that the editor qualities are calculated by the text qualities. To solve this problem, we mutually calculate the editor and text qualities until they converge. We did our experimental evaluation, and we confirmed that the proposed method could accurately assess the text qualities.",,https://dl.acm.org/doi/pdf/10.1145/2462932.2462956,https://dl.acm.org/doi/10.1145/2462932.2462956
61,"ACM, Google Scholar",Mining the Factors Affecting the Quality of Wikipedia Articles,2010,Kewen Wu; Qinghua Zhu; Y. Zhao; Hua Zheng,Conference,"2010 International Conference of Information Science and Management Engineering, 1, pp. 343-346",8,13,"In order to observe the variation of factors affecting the quality of Wikipedia articles during the information quality improvement process, we proposed 28 metrics from four aspects, including lingual, structural, historical and reputational features, and then weighted each metrics indifferent stages by using neural network. We found lingual features weighted more in the lower quality stages, and structural features, along with historical features, became more important while article quality improved. However, reputational features did not act as important as expected. The findings indicate that the information quality is mainly affected by completeness, and well-written is a basic requirement in the initial stage. Reputation of authors or editors is not so important in Wikipedia because of its horizontal structure.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5572324,https://ieeexplore.ieee.org/document/5572324
62,"Google Scholar, Web of Science",Measures for Quality Assessment of Articles and Infoboxes in Multilingual Wikipedia,2018,Włodzimierz Lewoniewski,Conference,"Business Information Systems, pp. 619-633",69,10,"One of the most popular collaborative knowledge bases on the Internet is Wikipedia. Articles of this free encyclopaedia are created and edited by users from different countries in about 300 languages. Depending on topic and language version, quality of information there may vary. This study presents and classifies measures that can be extracted from Wikipedia articles for the purpose of automatic quality assessment in different languages. Based on a state of the art analysis and own experiments, specific measures for various aspects of quality have been defined. Additional, in this work they were also defined measures for quality assessment of data contained in the structural parts of Wikipedia articles - infoboxes. This study describes also an extraction methods for various sources of measures, that can be used in quality assessment.",,https://link.springer.com/content/pdf/10.1007/978-3-030-04849-5_53,https://link.springer.com/chapter/10.1007/978-3-030-04849-5_53
64,"ACM, Google Scholar, Web of Science",Classifying Wikipedia Article Quality With Revision History Networks,2020,Narun K. Raman; Nathaniel Sauerberg; Jonah Fisher; Sneha Narayan,Conference,Proceedings of the 16th International Symposium on Open Collaboration,22,7,"We present a novel model for classifying the quality of Wikipedia articles based on structural properties of a network representation of the article's revision history. We create revision history networks (an adaptation of Keegan et. al's article trajectory networks [7]), where nodes correspond to individual editors of an article, and edges join the authors of consecutive revisions. Using descriptive statistics generated from these networks, along with general properties like the number of edits and article size, we predict which of six quality classes (Start, Stub, C-Class, B-Class, Good, Featured) articles belong to, attaining a classification accuracy of 49.35% on a stratified sample of articles. These results suggest that structures of collaboration underlying the creation of articles, and not just the content of the article, should be considered for accurate quality classification.",,https://dl.acm.org/doi/pdf/10.1145/3412569.3412581,https://dl.acm.org/doi/10.1145/3412569.3412581
65,"Google Scholar, Web of Science",WikipediaViz: Conveying article quality for casual Wikipedia readers,2010,Fanny Chevalier; Stéphane Huot; Jean-Daniel Fekete,Conference,"2010 IEEE Pacific Visualization Symposium (PacificVis), pp. 49-56",26,37,"As Wikipedia has become one of the most used knowledge bases worldwide, the problem of the trustworthiness of the information it disseminates becomes central. With WikipediaViz, we introduce five visual indicators integrated to the Wikipedia layout that can keep casual Wikipedia readers aware of important metainformation about the articles they read. The design of WikipediaViz was inspired by two participatory design sessions with expert Wikipedia writers and sociologists who explained the clues they used to quickly assess the trustworthiness of articles. According to these results, we propose five metrics for Maturity and Quality assessment of Wikipedia articles and their accompanying visualizations to provide the readers with important clues about the editing process at a glance. We also report and discuss about the results of the user studies we conducted. Two preliminary pilot studies show that all our subjects trust Wikipedia articles almost blindly. With the third study, we show that WikipediaViz significantly reduces the time required to assess the quality of articles while maintaining a good accuracy.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5429611,https://ieeexplore.ieee.org/document/5429611/
66,"Google Scholar, Web of Science",Multilingual Ranking of Wikipedia Articles with Quality and Popularity Assessment in Different Topics,2019,Włodzimierz Lewoniewski; Krzysztof Węcel; W. Abramowicz,Journal,"Comput., 8, pp. 60",90,22,"On Wikipedia, articles about various topics can be created and edited independently in each language version. Therefore, the quality of information about the same topic depends on the language. Any interested user can improve an article and that improvement may depend on the popularity of the article. The goal of this study is to show what topics are best represented in different language versions of Wikipedia using results of quality assessment for over 39 million articles in 55 languages. In this paper, we also analyze how popular selected topics are among readers and authors in various languages. We used two approaches to assign articles to various topics. First, we selected 27 main multilingual categories and analyzed all their connections with sub-categories based on information extracted from over 10 million categories in 55 language versions. To classify the articles to one of the 27 main categories, we took into account over 400 million links from articles to over 10 million categories and over 26 million links between categories. In the second approach, we used data from DBpedia and Wikidata. We also showed how the results of the study can be used to build local and global rankings of the Wikipedia content.",,https://pdfs.semanticscholar.org/d5b3/f3e9403eda8b45184951b269ee7997452c6b.pdf,https://www.mdpi.com/2073-431X/8/3/60
67,"ACM, Google Scholar, Web of Science",Automatically assessing the quality of Wikipedia contents,2019,Elias Bassani; Marco Viviani,Conference,Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing,27,6,"With the development of Web 2.0 technologies, people have gone from being mere content users to content generators. In this context, the evaluation of the quality of (potential) information available online has become a crucial issue. Nowadays, one of the biggest online resources that users rely on as a knowledge base is Wikipedia. The collaborative aspect at the basis of Wikipedia can let to the possible creation of low-quality articles or even misinformation if the process of monitoring the generation and the revision of articles is not performed in a precise and timely way. For this reason, in this paper, the problem of automatically evaluating the quality of Wikipedia contents is considered, by proposing a supervised approach based on Machine Learning to perform the classification of articles on qualitative bases. With respect to prior literature, a wider set of features connected to Wikipedia articles has been taken into account, as well as previously unconsidered aspects connected to the generation of a labeled dataset to train the model, and the use of Gradient Boosting, which produced encouraging results.",,https://dl.acm.org/doi/pdf/10.1145/3297280.3297357,https://dl.acm.org/doi/10.1145/3297280.3297357
70,"ACM, Google Scholar, Web of Science",Quality Evaluation of Wikipedia Articles through Edit History and Editor Groups,2010,SetsyWei Wang; M. Iwaihara,Conference,"Asia-Pacific Web Conference, pp. 188-199",18,16,"Wikipedia is well known as a free encyclopedia, which is a type of collaborative repository system that allows the viewer to create and edit articles directly in the web browser. The weakness of the Wikipedia system is the possibility of manipulation and vandalism cannot be ruled out, so that the quality of any given Wikipedia article is not guaranteed. It is an important work to establish a quality evaluation method to help users decide how much they should trust an article in Wikipedia. In this paper we investigate the edit history of Wikipedia articles and propose a model of network structure of editors. We propose an algorithm to calculate the network structural indicator restoreratio. We use the proposed indicator combined with existing metrics to predict the quality of Wikipedia articles through support vector machine technology. The experimental results show that the proposed indicator has better performance in quality evaluation than several existing metrics.",,https://link.springer.com/content/pdf/10.1007/978-3-642-20291-9_20.pdf,https://link.springer.com/chapter/10.1007/978-3-642-20291-9_20
71,"Google Scholar, Web of Science",Application of SEO Metrics to Determine the Quality of Wikipedia Articles and Their Sources,2018,Włodzimierz Lewoniewski; Ralf-Christian Härting; Krzysztof Węcel; Christopher Reichstein; W. Abramowicz,Conference,"International Conference on Information and Software Technologies, pp. 139-152",21,7,"The leading online encyclopedia Wikipedia is struggling with inconsistent article quality caused by the collaborative editing model. While one can find many helpful articles with consistent information on Wikipedia, there are also a lot of questionable articles with unclear or unfinished information yet. The quality of each article may vary over time as different users repeatedly re-edit content. One of the most important elements of the Wikipedia articles are references which allow to verify content and to show its source to user. Based on the fact that most of these references are web pages, it is possible to get more information about their quality by using citation analysis tools. For science and practice the empirical proof of the quality of the articles in Wikipedia could have a further signal effect, as the citation of Wikipedia articles, especially in scientific practice, is not yet recognised. This paper presents general results of Wikipedia analysis using metrics from the Toolbox SISTRIX, which is one of the leading providers of indicators for Search Engine Optimization (SEO). In addition to the preliminary analysis of the Wikipedia articles as separate web pages, we extracted data from more than 30 million references in different language versions of Wikipedia and analyzed over 180 thousand most popular hosts. In addition, we compared the same sources from different geographical perspectives using country-specific visibility indices.",,https://link.springer.com/content/pdf/10.1007/978-3-319-99972-2_11,https://link.springer.com/chapter/10.1007/978-3-319-99972-2_11
74,"ACM, Google Scholar, Web of Science",A deep learning-based quality assessment model of collaboratively edited documents: A case study of Wikipedia,2019,Ping Wang; Xiaodan Li; Renli Wu,Journal,"Journal of Information Science, 47, pp. 176 - 191",64,2,"Wikipedia is becoming increasingly critical in helping people obtain information and knowledge. Its leading advantage is that users can not only access information but also modify it. However, this presents a challenging issue: how can we measure the quality of a Wikipedia article? The existing approaches assess Wikipedia quality by statistical models or traditional machine learning algorithms. However, their performance is not satisfactory. Moreover, most existing models fail to extract complete information from articles, which degrades the model’s performance. In this article, we first survey related works and summarise a comprehensive feature framework. Then, state-of-the-art deep learning models are introduced and applied to assess Wikipedia quality. Finally, a comparison among deep learning models and traditional machine learning models is conducted to validate the effectiveness of the proposed model. The models are compared extensively in terms of their training and classification performance. Moreover, the importance of each feature and the importance of different feature sets are analysed separately.",,https://journals.sagepub.com/doi/pdf/10.1177/0165551519877646,https://journals.sagepub.com/doi/10.1177/0165551519877646
76,"ACM, Google Scholar",Automatically Labeling Low Quality Content on Wikipedia By Leveraging Patterns in Editing Behaviors,2021,Sumit Asthana; Sabrina Tobar Thommel; Aaron L Halfaker; Nikola Banovic,Conference,"Proceedings of the ACM on Human-Computer Interaction, 5, pp. 1 - 23",49,0,"Wikipedia articles aim to be definitive sources of encyclopedic content. Yet, only 0.6% of Wikipedia articles have high quality according to its quality scale due to insufficient number of Wikipedia editors and enormous number of articles. Supervised Machine Learning (ML) quality improvement approaches that can automatically identify and fix content issues rely on manual labels of individual Wikipedia sentence quality. However, current labeling approaches are tedious and produce noisy labels. Here, we propose an automated labeling approach that identifies the semantic category (e.g., adding citations, clarifications) of historic Wikipedia edits and uses the modified sentences prior to the edit as examples that require that semantic improvement. Highest-rated article sentences are examples that no longer need semantic improvements. We show that training existing sentence quality classification algorithms on our labels improves their performance compared to training them on existing labels. Our work shows that editing behaviors of Wikipedia editors provide better labels than labels generated by crowdworkers who lack the context to make judgments that the editors would agree with.",,https://dl.acm.org/doi/pdf/10.1145/3479503,https://dl.acm.org/doi/10.1145/3479503
78,"ACM, Google Scholar, Web of Science",Article quality classification on Wikipedia: introducing document embeddings and content features,2019,Manuel Schmidt; Eva Zangerle,Conference,Proceedings of the 15th International Symposium on Open Collaboration,24,5,"The quality of articles on the Wikipedia platform is vital for its success. Currently, the assessment of quality is performed manually by the Wikipedia community, where editors classify articles into pre-defined quality classes. However, this approach is hardly scalable and hence, approaches for the automatic classification have been investigated. In this paper, we extend this previous line of research on article quality classification by extending the set of features with novel content and edit features (e.g., document em-beddings of articles). We propose a classification approach utilizing gradient boosted trees based on this novel, extended set of features extracted from Wikipedia articles. Based on an established dataset containing Wikipedia articles and quality classes, we show that our approach is able to substantially outperform previous approaches (also including recent deep learning methods). Furthermore, we shed light on the contribution of individual features and show that the proposed features indeed capture the quality of an article well.",,https://dl.acm.org/doi/pdf/10.1145/3306446.3340831,https://dl.acm.org/doi/10.1145/3306446.3340831
79,"ACM, Google Scholar, Web of Science",Assessing quality score of Wikipedia article using mutual evaluation of editors and texts,2013,Yumiko Suzuki; M. Yoshikawa,Conference,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,8,17,"In this paper, we propose a method for assessing quality scores of Wikipedia articles by mutually evaluating editors and texts. Survival ratio based approach is a major approach to assessing article quality. In this approach, when a text survives beyond multiple edits, the text is assessed as good quality, because poor quality texts have a high probability of being deleted by editors. However, many vandals, low quality editors, delete good quality texts frequently, which improperly decreases the survival ratios of good quality texts. As a result, many good quality texts are unfairly assessed as poor quality. In our method, we consider editor quality score for calculating text quality score, and decrease the impact on text quality by vandals. Using this improvement, the accuracy of the text quality score should be improved. However, an inherent problem with this idea is that the editor quality scores are calculated by the text quality scores. To solve this problem, we mutually calculate the editor and text quality scores until they converge. In this paper, we prove that the text quality score converges. We did our experimental evaluation, and confirmed that our proposed method could accurately assess the text quality scores.",,https://dl.acm.org/doi/pdf/10.1145/2505515.2505610,https://dl.acm.org/doi/10.1145/2505515.2505610
82,Google Scholar,Quality Assessment of Wikipedia Articles Using h-index,2015,Yumiko Suzuki,Journal,"J. Inf. Process., 23, pp. 22-30",31,20,"In this paper, we propose a method for assessing quality values of Wikipedia articles from edit history using h-index. One of the major methods for assessing Wikipedia article quality is a peer-review based method. In this method, we assume that if an editor’s texts are left by the other editors, the texts are approved by the editors, then the editor is decided as a good editor. However, if an editor edits multiple articles, and the editor is approved at a small number of articles, the quality value of the editor deeply depends on the quality of the texts. In this paper, we apply h-index, which is a simple but resistant to excessive values, to the peer-review based Wikipedia article assessment method. Although h-index can identify whether an editor is a good quality editor or not, h-index cannot identify whether the editor is a vandal or an inactive editor. To solve this problem, we propose p-ratio for identifying which editors are vandals or inactive editors. From our experiments, we confirmed that by integrating h-index with p-ratio, the accuracy of article quality assessment in our method outperforms the existing peer-review based method.",,https://www.jstage.jst.go.jp/article/ipsjjip/23/1/23_22/_pdf,https://www.jstage.jst.go.jp/article/ipsjjip/23/1/23_22/_article
83,"ACM, Google Scholar, Web of Science",WikiLyzer: Interactive Information Quality Assessment in Wikipedia,2017,Cecilia di Sciascio; D. Strohmaier; M. Errecalde; Eduardo Veas,Conference,Proceedings of the 22nd International Conference on Intelligent User Interfaces,34,8,"Digital libraries and services enable users to access large amounts of data on demand. Yet, quality assessment of information encountered on the Internet remains an elusive open issue. For example, Wikipedia, one of the most visited platforms on the Web, hosts thousands of user-generated articles and undergoes 12 million edits/contributions per month. User-generated content is undoubtedly one of the keys to its success, but also a hindrance to good quality: contributions can be of poor quality because anyone, even anonymous users, can participate. Though Wikipedia has defined guidelines as to what makes the perfect article, authors find it difficult to assert whether their contributions comply with them and reviewers cannot cope with the ever growing amount of articles pending review. Great efforts have been invested in algorithmic methods for automatic classification of Wikipedia articles (as featured or non-featured) and for quality flaw detection. However, little has been done to support quality assessment of user-generated content through interactive tools that combine automatic methods and human intelligence. We developed WikiLyzer, a Web toolkit comprising three interactive applications designed to assist (i) knowledge discovery experts in creating and testing metrics for quality measurement, (ii) Wikipedia users searching for good articles, and (iii) Wikipedia authors that need to identify weaknesses to improve a particular article. A design study sheds a light on how experts could create complex quality metrics with our tool, while a user study reports on its usefulness to identify high-quality content.",,https://dl.acm.org/doi/pdf/10.1145/3025171.3025201,https://dl.acm.org/doi/10.1145/3025171.3025201
85,Google Scholar,An Edit-centric Approach for Wikipedia Article Quality Assessment,2019,Edison Marrese-Taylor; Pablo Loyola; Y. Matsuo,Conference,"Conference on Empirical Methods in Natural Language Processing, pp. 381-386",25,9,"We propose an edit-centric approach to assess Wikipedia article quality as a complementary alternative to current full document-based techniques. Our model consists of a main classifier equipped with an auxiliary generative module which, for a given edit, jointly provides an estimation of its quality and generates a description in natural language. We performed an empirical study to assess the feasibility of the proposed model and its cost-effectiveness in terms of data and quality requirements.",,https://aclanthology.org/D19-5550.pdf,https://aclanthology.org/D19-5550/
87,"Google Scholar, Web of Science",StRE: Self Attentive Edit Quality Prediction in Wikipedia,2019,Soumya Sarkar; Bhanu Prakash Reddy Guda; Sandipan Sikdar; Animesh Mukherjee,Conference,"ArXiv, abs/1906.04678",39,8,"Wikipedia can easily be justified as a behemoth, considering the sheer volume of content that is added or removed every minute to its several projects. This creates an immense scope, in the field of natural language processing toward developing automated tools for content moderation and review. In this paper we propose Self Attentive Revision Encoder (StRE) which leverages orthographic similarity of lexical units toward predicting the quality of new edits. In contrast to existing propositions which primarily employ features like page reputation, editor activity or rule based heuristics, we utilize the textual content of the edits which, we believe contains superior signatures of their quality. More specifically, we deploy deep encoders to generate representations of the edits from its text content, which we then leverage to infer quality. We further contribute a novel dataset containing ∼ 21M revisions across 32K Wikipedia pages and demonstrate that StRE outperforms existing methods by a significant margin – at least 17% and at most 103%. Our pre-trained model achieves such result after retraining on a set as small as 20% of the edits in a wikipage. This, to the best of our knowledge, is also the first attempt towards employing deep language models to the enormous domain of automated content moderation and review in Wikipedia.",,https://aclanthology.org/P19-1387.pdf,https://aclanthology.org/P19-1387/
89,"ACM, Google Scholar",Quality assessment of wikipedia articles: a deep learning approach,2016,DangQuang Vinh; IgnatClaudia-Lavinia,Journal,"ACM Sigweb Newsletter, ",30,5,"Wikipedia is indeed a very important knowledge sharing platform. However, since its start in 2001, the quality of Wikipedia is questioned because its content is created potentially by everyone who can access the Internet. Currently, the quality of Wikipedia articles is assessed by human judgement. The method is not scalable up to huge size and fast changing speed of Wikipedia today. An automatic quality classifier for Wikipedia articles is required to support user to choose high quality articles for reading and to notify authors for improving their products. While other existing approaches are based on manually predefined specific feature set, we present our approach of using deep learning to automatically represent Wikipedia articles for quality classification.",,https://dl.acm.org/doi/pdf/10.1145/2996442.2996447,https://dl.acm.org/doi/10.1145/2996442.2996447
90,"ACM, Google Scholar",Evaluating the trustworthiness of Wikipedia articles through quality and credibility,2009,S. Moturu; Huan Liu,Journal,N/A,9,18,"Wikipedia has become a very popular destination for Web surfers seeking knowledge about a wide variety of subjects. While it contains many helpful articles with accurate information, it also consists of unreliable articles with inaccurate or incomplete information. A casual observer might not be able to differentiate between the good and the bad. In this work, we identify the necessity and challenges for trust assessment in Wikipedia, and propose a framework that can help address these challenges by identifying relevant features and providing empirical means to meet the requirements for such an evaluation. We select relevant variables and perform experiments to evaluate our approach. The results demonstrate promising performance that is better than comparable approaches and could possibly be replicated with other social media applications.",,https://dl.acm.org/doi/pdf/10.1145/1641309.1641349,https://dl.acm.org/doi/10.1145/1641309.1641349
92,"Google Scholar, Web of Science",A matter of words: NLP for quality evaluation of Wikipedia medical articles,2016,V. Cozza; M. Petrocchi; A. Spognardi,Conference,"International Conference on Web Engineering, pp. 448-456",37,8,"Automatic quality evaluation of Web information is a task with many fields of applications and of great relevance, especially in critical domains, like the medical one. We move from the intuition that the quality of content of medical Web documents is affected by features related with the specific domain. First, the usage of a specific vocabulary (Domain Informativeness); then, the adoption of specific codes (like those used in the infoboxes of Wikipedia articles) and the type of document (e.g., historical and technical ones). In this paper, we propose to leverage specific domain features to improve the results of the evaluation of Wikipedia medical articles, relying on Natural Language Processing (NLP) and dictionaries-based techniques. The results of our experiments confirm that, by considering domain-oriented features, it is possible to improve existing solutions, mainly with those articles that other approaches have less correctly classified.",,https://link.springer.com/content/pdf/10.1007/978-3-319-38791-8_31,https://link.springer.com/chapter/10.1007/978-3-319-38791-8_31
95,"ACM, Google Scholar, Web of Science",Mining team characteristics to predict Wikipedia article quality,2016,Grace Gimon Betancourt; Armando Segnine; Carlos Trabuco; Amira Rezgui; Nicolas Jullien,Conference,Proceedings of the 12th International Symposium on Open Collaboration,46,8,"In this study, we were interested in studying which characteristics of virtual teams are good predictors for the quality of their production. The experiment involved obtaining the Spanish Wikipedia database dump and applying different data mining techniques suitable for large data sets to label the whole set of articles according to their quality (comparing them with the Featured/Good Articles, or FA/GA). Then we created the attributes that describe the characteristics of the team who produced the articles and using decision tree methods, we obtained the most relevant characteristics of the teams that produced FA/GA. The team's maximum efficiency and the total length of contribution are the most important predictors. This article contributes to the literature on virtual team organization.",,https://dl.acm.org/doi/pdf/10.1145/2957792.2971802,https://dl.acm.org/doi/10.1145/2957792.2971802
97,"ACM, Google Scholar","Quality Change: Norm or Exception? Measurement, Analysis and Detection of Quality Change in Wikipedia",2021,Paramita Das; Bhanu Prakash Reddy Guda; Sasi Bhusan Seelaboyina; Soumya Sarkar; Animesh Mukherjee,Conference,"Proceedings of the ACM on Human-Computer Interaction, 6, pp. 1 - 36",87,0,"Wikipedia has been turned into an immensely popular crowd-sourced encyclopedia for information dissemination on numerous versatile topics in the form of subscription free content. It allows anyone to contribute so that the articles remain comprehensive and updated. For enrichment of content without compromising standards, the Wikipedia community enumerates a detailed set of guidelines, which should be followed. Based on these, articles are categorized into several quality classes by the Wikipedia editors with increasing adherence to guidelines. This quality assessment task by editors is laborious as well as demands platform expertise. As a first objective, in this paper, we study evolution of a Wikipedia article with respect to such quality scales. Our results show novel non-intuitive patterns emerging from this exploration. As a second objective we attempt to develop an automated data driven approach for the detection of the early signals influencing the quality change of articles. We posit this as a change point detection problem whereby we represent an article as a time series of consecutive revisions and encode every revision by a set of intuitive features. Finally, various change point detection algorithms are used to efficiently and accurately detect the future change points. We also perform various ablation studies to understand which group of features are most effective in identifying the change points. To the best of our knowledge, this is the first work that rigorously explores English Wikipedia article quality life cycle from the perspective of quality indicators and provides a novel unsupervised page level approach to detect quality switch, which can help in automatic content monitoring in Wikipedia thus contributing significantly to the CSCW community.",,https://dl.acm.org/doi/pdf/10.1145/3512959,https://dl.acm.org/doi/10.1145/3512959
100,"Google Scholar, Web of Science",Quality flaw prediction in Spanish Wikipedia: A case of study with verifiability flaws,2018,E. Ferretti; L. Cagnina; Viviana Paiz; Sebastián Delle Donne; Rodrigo Zacagnini; M. Errecalde,Journal,"Inf. Process. Manag., 54, pp. 1169-1181",38,8,"In this work, we present the first quality flaw prediction study for articles containing the two most frequent verifiability flaws in Spanish Wikipedia: articles which do not cite any references or sources at all (denominated Unreferenced) and articles that need additional citations for verification (so-called Refimprove). Based on the underlying characteristics of each flaw, different state-of-the-art approaches were evaluated. For articles not citing any references, a well-established rule-based approach was evaluated and interesting findings show that some of them suffer from Refimprove flaw instead. Likewise, for articles that need additional citations for verification, the well-known PU learning and one-class classification approaches were evaluated. Besides, new methods were compared and a new feature was also proposed to model this latter flaw. The results showed that new methods such as under-bagged decision trees with sum or majority voting rules, biased-SVM, and centroid-based balanced SVM, perform best in comparison with the ones previously published.",,https://reader.elsevier.com/reader/sd/pii/S0306457317309329?token=932F3ED2D2166622793C94EF06681099A807E81123D2C8A2103641E6DFA3906BCFCA8A59AF7D631C3F1183491945618F&originRegion=eu-west-1&originCreation=20230130113926,https://www.sciencedirect.com/science/article/pii/S0306457317309329?via%3Dihub
101,"ACM, Google Scholar, Web of Science",Structural Analysis of Wikigraph to Investigate Quality Grades of Wikipedia Articles,2021,Anamika Chhabra; S. Srivastava; S. Iyengar; P. Saini,Conference,Companion Proceedings of the Web Conference 2021,46,1,"The quality of Wikipedia articles is manually evaluated which is time inefficient as well as susceptible to human bias. An automated assessment of these articles may help in minimizing the overall time and manual errors. In this paper, we present a novel approach based on the structural analysis of Wikigraph to automate the estimation of the quality of Wikipedia articles. We examine the network built using the complete set of English Wikipedia articles and identify the variation of network signatures of the articles with respect to their quality. Our study shows that these signatures are useful for estimating the quality grades of un-assessed articles with an accuracy surpassing the existing approaches in this direction. The results of the study may help in reducing the need for human involvement for quality assessment tasks.",,https://dl.acm.org/doi/pdf/10.1145/3442442.3452345,https://dl.acm.org/doi/10.1145/3442442.3452345
106,"Google Scholar, Web of Science",Relative Quality Assessment of Wikipedia Articles in Different Languages Using Synthetic Measure,2017,Włodzimierz Lewoniewski; Krzysztof Węcel,Conference,"Business Information Systems, pp. 282-292",16,5,"Online encyclopedia Wikipedia is one of the most popular sources of knowledge. It is often criticized for poor information quality. Articles can be created and edited even by anonymous users independently in almost 300 languages. Therefore, a difference in the information quality in various language versions on the same topic is observed. The Wikipedia community has created a system for assessing the quality of articles, which can be helpful in deciding which language version is more complete and correct. There are several issues: each Wikipedia language can use own grading scheme and there is usually a large number of unevaluated articles. In this paper, we propose to use a synthetic measure for automatic quality evaluation of the articles in different languages based on important features",,https://www.researchgate.net/publication/320446880_Relative_Quality_Assessment_of_Wikipedia_Articles_in_Different_Languages_Using_Synthetic_Measure,https://link.springer.com/chapter/10.1007/978-3-319-69023-0_24
109,"Google Scholar, Web of Science",Enrichment of Information in Multilingual Wikipedia Based on Quality Analysis,2017,Włodzimierz Lewoniewski,Conference,"Business Information Systems, pp. 216-227",33,7,"Despite the fact that Wikipedia is one of the most popular sources of information in the world, it is often criticized for the poor quality of content. In this online encyclopaedia articles on the same topic can be created and edited independently in different languages. Some of this language versions can provide valuable information on a specific topics. Wikipedia articles may include infobox, which used to collect and present a subset of important information about its subject. This study presents method for quality assessment of Wikipedia articles and information contained in their infoboxes. Choosing the best language versions of a particular article will allow for enrichment of information in less developed version editions of particular articles.",,http://lewoniewski.info/files/bis2017_wiki_enrichment.pdf,https://link.springer.com/chapter/10.1007/978-3-319-69023-0_19
111,"ACM, Google Scholar",GreenWiki: a tool to support users' assessment of the quality of Wikipedia articles,2011,D. H. Dalip; R. L. Santos; Diogo Rennó Rocha de Oliveira; Valéria Freitas Amaral; Marcos André Gonçalves; R. Prates; R. Minardi; J. Almeida,Conference,"ACM/IEEE Joint Conference on Digital Libraries, pp. 469-470",4,4,"In this work, we present GreenWiki, which is a wiki with a panel of quality indicators to assist the reader of a Wikipedia article in assessing its quality.",,https://dl.acm.org/doi/pdf/10.1145/1998076.1998190,https://dl.acm.org/doi/10.1145/1998076.1998190
114,Google Scholar,An Empirical Study to Predict the Quality of Wikipedia Articles,2019,Imran Khan; Shahid Hussain; Hina Gul; Muhammad Shahid; Muhammad Jamal,Conference,"WorldCIST, pp. 485-492",19,3,"Wikipedia is considered a common way to deliver content in a more effective way as compared to other types of an encyclopedia. However, the quality threat remains an issue regarding the Wikipedia articles. The basic aim of propose research to perform an empirical study to predict the quality of Wikipedia articles. In the proposed methodology, we consider few metrics such as article length (total number of word in an article), number of edits, article age (in the day) and article ranking and perform few statistical tests analyze the quality of Wikipedia articles. Moreover, we observe a significant correlation of proposed metrics with the rating of articles in order to identify their quality. 
",,https://link.springer.com/content/pdf/10.1007/978-3-030-16187-3_47,https://link.springer.com/chapter/10.1007/978-3-030-16187-3_47
115,Google Scholar,On the Use of PU Learning for Quality Flaw Prediction in Wikipedia,2012,E. Ferretti; D. H. Fusilier; R. Guzmán-Cabrera; M. Montes-y-Gómez; M. Errecalde; Paolo Rosso,Conference,"Conference and Labs of the Evaluation Forum, 1178",18,14,"In this article we describe a new approach to assess Quality Flaw Prediction in Wikipedia. The partially supervised method studied, called PU Learning, has been successfully applied in classifications tasks with traditional corpora like Reuters-21578 or 20-Newsgroups. To the best of our knowledge, this is the first time that it is applied in this domain. Throughout this paper, we describe how the original PU Learning approach was evaluated for assessing quality flaws and the modifications introduced to get a quality flaws predictor which obtained the best F1 scores in the task “Quality Flaw Prediction in Wikipedia” of the PAN challenge",,https://ceur-ws.org/Vol-1178/CLEF2012wn-PAN-FerrettiEt2012.pdf,https://www.researchgate.net/publication/236565329_On_the_Use_of_PU_Learning_for_Quality_Flaw_Prediction_in_Wikipedia
117,"ACM, Google Scholar",QualityRank: assessing quality of wikipedia articles by mutually evaluating editors and texts,2012,Yumiko Suzuki; M. Yoshikawa,Conference,"ACM Conference on Hypertext & Social Media, pp. 307-308",4,7,"In this paper, we propose a method to identify high-quality Wikipedia articles by mutually evaluating editors and texts. A major approach for assessing articles using edit history is a text survival ratio based approach. However, the problem is that many high-quality articles are identified as low quality, because many vandals delete high-quality texts, then the survival ratios of high-quality texts are decreased by vandals. Our approach's strongest point is its resistance to vandalism. Using our method, if we calculate text quality values using editor quality values, vandals do not affect any quality values of the other editors, then the accuracy of text quality values should improve. However, the problem is that editor quality values are calculated by text quality values, and text quality values are calculated by editor quality values. To solve this problem, we mutually calculate editor and text quality values until they converge. Using this method, we can calculate a quality value of a text that takes into consideration that of its editors.",,https://dl.acm.org/doi/pdf/10.1145/2309996.2310047,https://dl.acm.org/doi/10.1145/2309996.2310047
118,Google Scholar,,,,,,,,,,,
119,"Google Scholar, Web of Science",Assessing Information Quality of Wikipedia Articles through Google’s E-A-T Model,2022,Chinthani Sugandhika; S. Ahangama,Journal,"IEEE Access, PP, pp. 1-1",58,1,"Along with the emergence of Web 2.0, User Generated Content (UGC) is becoming increasingly important for knowledge sharing. Wikipedia being the world’s largest-ever community-based collaborative encyclopedia, is also one of the biggest UGC databases in the world. Wikipedia is dealing with a significant problem of Information Quality (IQ) because of its open-source and collaborative nature. When carrying out attacks such as link spamming, malicious users take advantage of Wikipedia’s popularity on the WWW. As a result, Wikipedia is generally not recommended for academic-related work. There are, however, some articles that are both rich in information and quality. Existing approaches for assessing Wikipedia’s IQ involve statistical models and machine learning algorithms; however, the existing models do not produce satisfactory results. In this study, a novel theoretical model based on Google’s E-A-T framework is introduced to assess Wikipedia’s IQ. The model comprises three IQ constructs Expertise, Authority and Trustworthiness. Based on the empirical findings and study results, a set of IQ dimensions that influence the above three IQ constructs, as well as 45 IQ attributes to measure the IQ dimensions, were identified. The IQ attributes were automatically and inexpensively extracted from the content and meta-data statistics of Wikipedia articles using a Selenium 3.14 web automation script. A sample of 2000 articles comprising 1000 Featured Articles (FA) and 1000 non-FA articles from six WikiProjects was used for the data analysis. The proposed model was compared with three previously published models in terms of classification and clustering accuracy. It received classification and clustering accuracies of 95% and 93% respectively which is a drastic improvement over the existing models. Furthermore, an average inter-rater agreement of 84% was observed. Thus, the proposed model’s effectiveness is fairly validated by this extensive experiment. This study contributes to the related knowledge area by introducing a novel framework to assess Wikipedia articles’ IQ. The study’s limitations include the domain specificity of the chosen dataset and focusing solely on the English language. However, the results can be generalized by improving the dataset by size and replicating the study for the other domains and languages supported by Wikipedia.",,https://ieeexplore.ieee.org/ielx7/6287639/6514899/09770051.pdf,https://ieeexplore.ieee.org/document/9770051
122,Google Scholar,Measuring Quality of Wikipedia Articles by Feature Fusion‐based Stack Learning,2021,Jingrui Hou; Jiangnan Li; Ping Wang,Conference,"Proceedings of the Association for Information Science and Technology, 58",61,1,"Online open‐source knowledge repository such as Wikipedia has become an increasingly important source for users to access knowledge. However, due to its large volume, it is challenging to evaluate Wikipedia article quality manually. To fill this gap, we propose a novel approach named “feature fusion‐based stack learning” to assess the quality of Wikipedia articles. Pre‐trained language models including BERT (Bidirectional Encoder Representations from Transformers) and ELMo (Embeddings from Language Models) are applied to extract semantic information in Wikipedia content. The feature fusion framework consisting of semantic and statistical features is built and fed into an out‐of‐sample (OOS) stacking model, which includes both machine learning and deep learning models. We compare the performance of proposed model with some existing models with different metrics extensively, and conduct ablation studies to prove the effectiveness of our framework and OOS stacking. Generally, the experiment shows that our method is much better than state‐of‐the‐art models.",,,https://asistdl.onlinelibrary.wiley.com/doi/10.1002/pra2.449
125,"ACM, Google Scholar","How do metrics of link analysis correlate to quality, relevance and popularity in wikipedia?",2013,Raíza Hanada; Marco Cristo; M. G. Pimentel,Conference,"Brazilian Symposium on Multimedia and the Web, pp. 105-112",14,10,"Many links between Web pages can be viewed as indicative of the quality and importance of the pages they pointed to. Accordingly, several studies have proposed metrics based on links to infer web page content quality. However, as far as we know, the only work that has examined the correlation between such metrics and content quality consisted of a limited study that left many open questions. In spite of these metrics having been shown successful in the task of ranking pages which were provided as answers to queries submitted to search engines, it is not possible to determine the specific contribution of factors such as quality, popularity, and importance to the results. This difficulty is partially due to the fact that such information is hard to obtain for Web pages in general. Unlike ordinary Web pages, the quality, importance and popularity of Wikipedia articles are evaluated by human experts or might be easily estimated. Thus, it is feasible to verify the relation between link analysis metrics and such factors in Wikipedia articles, our goal in this work. To accomplish that, we implemented several link analysis algorithms and compared their resulting rankings with the ones created by human evaluators regarding factors such as quality, popularity and importance. We found that the metrics are more correlated to quality and popularity than to importance, and the correlation is moderate.",,https://dl.acm.org/doi/pdf/10.1145/2526188.2526198,https://dl.acm.org/doi/10.1145/2526188.2526198
128,"Google Scholar, Web of Science",A Psycho-Lexical Approach to the Assessment of Information Quality on Wikipedia,2015,Qi Su; Pengyuan Liu,Conference,"2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), 3, pp. 184-187",18,5,"The great popularity of Wikipedia makes it one of the dominant knowledge source around the World. However, since one of the core principles of Wikipedia is being open for anyone to maintain it, Wikipedia cannot fully ensure the reliability of its articles, and thus sometimes suffered criticism for containing low-quality information. It is therefore essential to assess the quality of Wikipedia articles automatically. In this paper we describe how we approach that problem by using a psycho-lexical resource, i.e., the Language Inquiry and Word Count (LIWC) dictionary. By training a classifier on different LIWC categories, we discuss the implications of each category for Wikipedia quality assessment.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7397452,https://ieeexplore.ieee.org/document/7397452
130,Google Scholar,,,,,,,,,,,
131,Google Scholar,Assessing the Quality of Wikipedia Pages Using Edit Longevity and Contributor Centrality,2012,Xiangju Qin; P. Cunningham,Journal,"ArXiv, abs/1206.2517",20,5,"In this paper we address the challenge of assessing the quality of Wikipedia pages using scores derived from edit contribution and con- tributor authoritativeness measures. The hypothesis is that pages with significant contributions from authoritative contributors are likely to be high-quality pages. Contributions are quantified using edit longevity measures and contributor authoritativeness is scored using centrality metrics in either the Wikipedia talk or co-author networks. The results suggest that it is useful to take into account the contributor authori- tativeness when assessing the information quality of Wikipedia content. The percentile visualization of the quality scores provides some insights about the anomalous articles, and can be used to help Wikipedia editors to identify Start and Stub articles that are of relatively good quality.",,https://arxiv.org/pdf/1206.2517.pdf,https://arxiv.org/abs/1206.2517
132,"Google Scholar, Web of Science",Towards Information Quality Assurance in Spanish: Wikipedia,2017,E. Ferretti; M. Soria; Sebastián Pérez Casseignau; Lian Pohn; Guido Urquiza; Sergio Alejandro Gómez; M. Errecalde,Journal,"Journal of Computer Science and Technology, 17, pp. 29-36",17,4,"Featured Articles (FA) are considered to be the best articles that Wikipedia has to offer and in the last years, researchers have found interesting to analyze whether and how they can be distinguished from “ordinary” articles. Likewise, identifying what issues have to be enhanced or fixed in ordinary articles in order to improve their quality is a recent key research trend. Most of the approaches developed to face these information quality problems have been proposed for the English Wikipedia. However, few efforts have been accomplished in Spanish Wikipedia, despite being Spanish, one of the most spoken languages in the world by native speakers. In this respect, we present a breakdown of Spanish Wikipedia’s quality flaw structure. Besides, we carry out studies with three different corpora to automatically assess information quality in Spanish Wikipedia, where FA identification is evaluated as a binary classification task. Our evaluation on a unified setting allows to compare with the English version, the performance achieved by our approach on the Spanish version. The best results obtained show that FA identification in Spanish, can be performed with an F1 score of 0.88 using a document model consisting of only twenty six features and Support Vector Machine as classification algorithm.",,https://host170.sedici.unlp.edu.ar/server/api/core/bitstreams/6908402f-f564-4313-aa26-a121a593a2a6/content,https://www.semanticscholar.org/paper/8cba1878de84959de7a5401c9181819ee9bdf205
133,Google Scholar,Effects of Implicit Positive Ratings for Quality Assessment of Wikipedia Articles,2013,Yumiko Suzuki,Journal,"J. Inf. Process., 21, pp. 342-348",22,3,"In this paper, we propose a method to identify high-quality Wikipedia articles by using implicit positive ratings. One of the major approaches for assessing Wikipedia articles is a text survival ratio based approach. In this approach, when a text survives beyond multiple edits, the text is assessed as high quality. However, the problem is that many low quality articles are misjudged as high quality, because every editor does not always read the whole article. If there is a low quality text at the bottom of a long article, and the text has not seen by the other editors, then the text survives beyond many edits, and the text is assessed as high quality. To solve this problem, we use a section and a paragraph as a unit instead of a whole page. In our method, if an editor edits an article, the system considers that the editor gives positive ratings to the section or the paragraph that the editor edits. From experimental evaluation, we confirmed that the proposed method could improve the accuracy of quality values for articles.",,https://www.jstage.jst.go.jp/article/ipsjjip/21/2/21_342/_pdf,https://www.jstage.jst.go.jp/article/ipsjjip/21/2/21_342/_article
136,"ACM, Google Scholar",Assessing the Quality of Wikipedia Articles,2021,Quang-Vinh Dang,Conference,2021 The 5th International Conference on Machine Learning and Soft Computing,47,0,"Wikipedia is a very important information reference source for the Internet users. Due to the fact that the content of Wikipedia is the collaborative result from a massive number of participants all over the world, the quality of Wikipedia might be questionable. Over the last decade, many research works are dedicated to solve the issue of Wikipedia quality. In this paper, we present our latest research in determining the quality of Wikipedia articles. The evaluation on the real-world dataset shows that our method outperforms other baseline methods proposed recently.",,https://dl.acm.org/doi/pdf/10.1145/3453800.3453801,https://dl.acm.org/doi/10.1145/3453800.3453801
139,"Google Scholar, Web of Science",Using Morphological and Semantic Features for the Quality Assessment of Russian Wikipedia,2017,Włodzimierz Lewoniewski; N. Khairova; Krzysztof Węcel; Nataliia Stratiienko; W. Abramowicz,Conference,"International Conference on Information and Software Technologies, pp. 550-560",19,3,"Nowadays, the assessment of the quality and credibility of Wikipedia articles becomes increasingly important. We propose to use morphological and semantic features to estimate the quality of Wikipedia articles in Russian language. We distinguished over 150 linguistic features and divided them into four groups. In these groups, we considered the features of encyclopedic style, readability and subjectivism of the article’s text. Based on Random Forest as a classification algorithm, we show the most importance linguistic features that affect the quality of Russian Wikipedia articles. We compare the classification results of our four linguistic features groups separately. We have achieved the F-measure of 89,75%.",,https://link.springer.com/content/pdf/10.1007/978-3-319-67642-5_46.pdf,https://link.springer.com/chapter/10.1007/978-3-319-67642-5_46
142,"ACM, Google Scholar, Web of Science",Quality Assessment of Peer-Produced Content in Knowledge Repositories Using Big Data and Social Networks: The Case of Implicit Collaboration in Wikipedia,2019,Srikar Velichety,Journal,"Data Base, 50, pp. 28-51",79,1,"This research provides a method for quality assessment of peer-produced content in knowledge repositories using a complementary view of collaboration. Using the definition of collaboration as the action of working with someone to produce something, we identify the aspects of collaboration that the present research on online communities does not consider. To this end, we introduce and define the concept of implicit collaboration and then identify two dimensions and four possible areas of collaboration. In each area, we identify the relevant social network that captures collaboration. Using customized measures on each of the networks that capture various aspects of collaboration, we quantify the utility of implicit collaboration in assessing article quality. Experiments conducted on the complete population of graded English language Wikipedia articles show that all the identified measures improve the predictive accuracy of the existing models by 11.89 percent while improving the class-wise precision by 9-18 percent and the class-wise recall by 5-26 percent. We also find that our method complements the existing quality assessment approaches well. Our research has implications for developing automated quality assessment methods for peer-produced content using big data and social networks.",,https://dl.acm.org/doi/pdf/10.1145/3371041.3371045,https://dl.acm.org/doi/10.1145/3371041.3371045
145,"ACM, Google Scholar, Web of Science",Equal opportunities in the access to quality online health information? A multi-lingual study on Wikipedia,2021,Luis Couto; C. Lopes,Conference,Proceedings of the 17th International Symposium on Open Collaboration,38,1,"Wikipedia is a free, multilingual, and collaborative online encyclopedia. Nowadays, it is one of the largest sources of online knowledge, often appearing at the top of the results of the major search engines, being one of the most sought-after resources by the public searching for health information. The collaborative nature of Wikipedia raises security concerns since this information is used for decision-making, especially in the health area. Despite being available in hundreds of idioms, there are asymmetries between idioms, namely regarding their quality. In this work, we compare the quality of health information on Wikipedia between idioms with 100 million native speakers or more, and also in Greek, Italian, Korean, Turkish, Persian, Catalan and Hebrew, for historical tradition. Quality metrics are applied to health and medical articles in English, maintained by WikiProject Medicine, and their versions in the above idioms. With this, we contribute to a clarification of the role of Wikipedia in the access to health information. We demonstrate differences in both the quantity and quality of information available between idioms. English is the idiom with the highest quality in general. Urdu, Greek, Indonesian, and Hindi achieved lower values of quality.",,https://dl.acm.org/doi/pdf/10.1145/3479986.3480000,https://dl.acm.org/doi/10.1145/3479986.3480000
147,Google Scholar,Predicting Information Quality Flaws in Wikipedia by Using Classical and Deep Learning Approaches,2019,Gerónimo Bazán Pereyra; C. Cuello; G. Capodici; Vanessa Jofré; E. Ferretti; Rodolfo Bonnin; M. Errecalde,Conference,"Argentine Congress of Computer Science, pp. 3-18",31,2,"Quality flaws prediction in Wikipedia is an ongoing research trend. In particular, in this work we tackle the problem of automatically predicting five out of the ten most frequent quality flaws; namely: No footnotes, Notability, Primary Sources, Refimprove and Wikify. Different classical and deep learning state-of-the-art approaches were studied. From among the evaluated approaches, some of them always reach or improve the existing benchmarks on the test corpus from the 1st International Competition on Quality Flaw Prediction in Wikipedia; a well-known uniform evaluation corpus from this research field. Particularly, the results showed that under-bagged decision trees with different aggregation rules perform best improving the existing benchmarks for four out the five flaws.",,https://link.springer.com/content/pdf/10.1007/978-3-030-48325-8_1,https://link.springer.com/chapter/10.1007/978-3-030-48325-8_1
148,"Google Scholar, Web of Science",Quality assessment of Arabic web content: The case of the Arabic Wikipedia,2014,A. Yahya; A. Salhi,Conference,"2014 10th International Conference on Innovations in Information Technology (IIT), pp. 36-41",16,3,"With the huge size and large diversity of Arabic web content, machine assessment of document quality acquires added importance. Users are in dire need for quality rating of the material returned in response to their queries. The Wikipedia, with its large metadata, has been a topic of extensive research on document quality assessment. Criteria used include text properties and style parameters, contributor and edit characteristics and multimedia components. In this paper we report on our ongoing work to adapt existing document assessment approaches to Arabic content with concentration on the Arabic Wikipedia and present some of the results. We also try to augment that with features specific to Arabic as well as parameters like author expertise and social media presence. One of our goals is an aggregate measure integrating many of the features into a single document quality index. We plan to use Wikipedia article quality assessment results to train general content assessment methods that can be applied to general content that lacks major Wikipedia features.",,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987558,https://ieeexplore.ieee.org/document/6987558
149,"Google Scholar, Web of Science",Determining Quality of Articles in Polish Wikipedia Based on Linguistic Features,2018,Włodzimierz Lewoniewski; Krzysztof Węcel; W. Abramowicz,Conference,"International Conference on Information and Software Technologies, pp. 546-558",25,2,"Wikipedia is the most popular and the largest user-generated source of knowledge on the Web. Quality of the information in this encyclopedia is often questioned. Therefore, Wikipedians have developed an award system for high quality articles, which follows the specific style guidelines. Nevertheless, more than 1.2 million articles in Polish Wikipedia are unassessed. This paper considers over 100 linguistic features to determine the quality of Wikipedia articles in Polish language. We evaluate our models on 500 000 articles of Polish Wikipedia. Additionally, we discuss the importance of linguistic features for quality prediction.",,https://link.springer.com/content/pdf/10.1007/978-3-319-99972-2_45,https://link.springer.com/chapter/10.1007/978-3-319-99972-2_45
150,"Google Scholar, Web of Science",Quality Classification of ASEAN Wikipedia Articles using Statistical Features,2018,Kanchana Saengthongpattana; T. Supnithi; N. Soonthornphisaj,Conference,"2018 International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP), pp. 1-6",11,1,"The quality of Wikipedia articles is still the main concerned in all languages. Wikipedia relies mostly on human editors and administrators to provide the quality of content. But the magnitude of Wikipedia content makes locating all instances of article very time consuming. Therefore, we need the automatic quality detection that can help users to evaluate the quality of articles. In this paper, we propose the feature set to applied for the ASEAN language Wikipedia articles. We investigate the statistical features such as # of link, # of infobox, length of article, # of headings, # of files, # of contributors, # of viewer, # of written articles found in other languages, and # of templates applied in the article. The experiments are perform using Naïve Bayes and Decision tree algorithm. We found that the accuracy of Decision tree (96.34%) outperform Naïve Bayes (86.47%). Moreover, we found that the statistical features play an important role in quality classification of Vietnamese, Indonesian, Malaysian, Thai, and Tagalog/Philippines Wikipedia articles.",,https://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=8692954&ref=,https://ieeexplore.ieee.org/document/8692954/
155,"Google Scholar, Web of Science",Cumulative Experience and Recent Behavior and their Relation to Content Quality on Wikipedia,2017,Michail Tsikerdekis,Journal,"Interact. Comput., 29, pp. 737-754",69,1,"Cumulative experience is often seen as a major factor for influencing content quality in collaborative projects such as Wikipedia. However, past studies often utilize cumulative experience based on the quantity of work rather than quality and context. Moreover, the perspective on cumulative experience assumes a final destination for user behavior, whereas much of the literature indicates that user behavior changes over time. This paper aims to address these two factors by providing better descriptions and context to determine their effect on content quality. The study rematerialized these factors based on 1 Communications Facility 495, 516 High Street, Bellingham, WA 98225. U.S.A. Telephone: 360-6502401, Email: michael.tsikerdekis@wwu.edu",,https://academic.oup.com/iwc/article/29/5/737/3885842,https://academic.oup.com/iwc/article/29/5/737/3885842
157,"Google Scholar, Web of Science",On Quality Assesement in Wikipedia Articles Based on Markov Random Fields,2017,Rajmund Kleminski; Tomasz Kajdanowicz; Roman Bartusiak; Przemyslaw Kazienko,Conference,"Asian Conference on Intelligent Information and Database Systems, pp. 782-791",13,1,"This article investigates the possibility of accurate quality prediction of resources generated by communities based on the crowd-generated content. We use data from Wikipedia, the prime example of community-run site, as our object of study. We define the quality as a distribution of user-assigned grades across a predefined range of possible scores and present a measure of distribution similarity to quantify the accuracy of a prediction. The proposed method of quality prediction is based on Markov Random Field and its Loopy Belief Propagation implementation. Based on our results, we highlight key problems in the approach as presented, as well as trade-offs caused by relying solely on network structure and characteristics, excluding metadata. The overall results of content quality prediction are promising in homophilic networks.",,https://link.springer.com/content/pdf/10.1007/978-3-319-54472-4_73,https://link.springer.com/chapter/10.1007/978-3-319-54472-4_73
159,Google Scholar,Assessing Quality Values of Wikipedia Articles Using Implicit Positive and Negative Ratings,2012,Yumiko Suzuki,Conference,"Interational Conference on Web-Age Information Management, pp. 127-138",10,1,"In this paper, we propose a method to identify high-quality Wikipedia articles by mutually evaluating editors and text using implicit positive and negative ratings. One of major approaches for assessing Wikipedia articles is a text survival ratio based approach. However, the problem of this approach is that many low quality articles are misjudged as high quality, because of two issues. This is because, every editor does not always read the whole articles. Therefore, if there is a low quality text at the bottom of a long article, and the text have not seen by the other editors, then the text survives beyond many edits, and the survival ratio of the text is high. To solve this problem, we use a section or a paragraph as a unit of remaining instead of a whole page. This means that if an editor edits an article, the system treats that the editor gives positive ratings to the section or the paragraph that the editor edits. This is because, we believe that if editors edit articles, the editors may not read the whole page, but the editors should read the whole sections or paragraphs, and delete low-quality texts. From experimental evaluation, we confirmed that the proposed method could improve the accuracy of quality values for articles. ",,https://link.springer.com/content/pdf/10.1007/978-3-642-32281-5_13,https://link.springer.com/chapter/10.1007/978-3-642-32281-5_13
160,Google Scholar,On the Assessment of Information Quality in Spanish Wikipedia,2016,Guido Urquiza; M. Soria; Sebastián Pérez Casseignau; E. Ferretti; Sergio Alejandro Gómez; M. Errecalde,Journal,N/A,20,3,"Featured Articles (FA) are considered to be the best articles that Wikipedia has to offer and in the last years, researchers have found interesting to analyze whether and how they can be distinguished from “ordinary” articles. Likewise, identifying what issues have to be enhanced or fixed in ordinary articles in order to improve their quality is a recent key research trend. Most of the approaches developed in these research trends have been proposed for the English Wikipedia. However, few efforts have been accomplished in Spanish Wikipedia, despite being Spanish, one of the most spoken languages in the world by native speakers. In this respect, we present a first breakdown of Spanish Wikipedia’s quality flaw structure. Besides, we carry out a study to automatically assess information quality in Spanish Wikipedia, where FA identification is evaluated as a binary classification task. The results obtained show that FA identification can be performed with an F1 score of 0.81, using a document model consisting of only twenty six features and AdaBoosted C4.5 decision trees as classification algorithm.",,http://sedici.unlp.edu.ar/bitstream/handle/10915/56750/Documento_completo.pdf-PDFA.pdf?isAllowed=y&sequence=1,http://sedici.unlp.edu.ar/handle/10915/56750
161,"ACM, Google Scholar, Web of Science",Assessing the quality of health-related Wikipedia articles with generic and specific metrics,2021,Luis Couto; C. Lopes,Conference,Companion Proceedings of the Web Conference 2021,30,1,"Wikipedia is an online, free, multi-language, and collaborative encyclopedia, currently one of the most significant information sources on the web. The open nature of Wikipedia contributions raises concerns about the quality of its information. Previous studies have addressed this issue using manual evaluations and proposing generic measures for quality assessment. In this work, we focus on the quality of health-related content. For this purpose, we use general and health-specific features from Wikipedia articles to propose health-specific metrics. We evaluate these metrics using a set of Wikipedia articles previously assessed by WikiProject Medicine. We conclude that it is possible to combine generic and specific metrics to determine health-related content’s information quality. These metrics are computed automatically and can be used by curators to identify quality issues. Along with the explored features, these metrics can also be used in approaches that automatically classify the quality of Wikipedia health-related articles.",,https://dl.acm.org/doi/pdf/10.1145/3442442.3452355,https://dl.acm.org/doi/10.1145/3442442.3452355
162,Google Scholar,Ontology-Based Classifiers for Wikipedia Article Quality Classification,2017,Kanchana Saengthongpattana; T. Supnithi; N. Soonthornphisaj,Journal,Advances in Intelligent Systems and Computing,18,1,Quality of Wikipedia article is the main issues that need to be solved. This research proposes the ontology-based classification framework that considers the quality of article in term of its comprehensive content which is one of the properties for featured and good articles in Thai Wikipedia. We create concepts or main ideas of articles in three domains using ontology as a knowledge representation. Knowledge based are created using OAM tool that do data mapping and classify the quality of articles via set of rules. We have investigated the ontology approach which combined Naive Bayes classifier and found that the precision of our proposed method outperform traditional Naive Bayes for two times.,,https://link.springer.com/content/pdf/10.1007/978-3-319-94703-7_7,https://link.springer.com/chapter/10.1007/978-3-319-94703-7_7
169,"Google Scholar, Web of Science",Assessing the Quality of Thai Wikipedia Articles Using Concept and Statistical Features,2014,Kanchana Saengthongpattana; N. Soonthornphisaj,Conference,"WorldCIST, pp. 513-523",10,2,"The quality evaluation of Thai Wikipedia articles relies on user consideration. There are increasing numbers of articles every day therefore the automatic evaluation method is needed for user. Components of Wikipedia articles such as headers, pictures, references, and links are useful to indicate the quality of articles. However readers need complete content to cover all of concepts in that article. The concept features are investigated in this work. The aim of this research is to classify Thai Wikipedia articles into two classes namely high-quality and low-quality class. Three article domains (Biography, Animal, and Place) are testes with decision tree and Naive Bayes. We found that Naive Bayes gets high TP Rate compared to decision tree in every domain. Moreover, we found that the concept feature plays an important role in quality classification of Thai Wikipedia articles. ",,https://link.springer.com/content/pdf/10.1007/978-3-319-05951-8_49,https://link.springer.com/chapter/10.1007/978-3-319-05951-8_49
172,Google Scholar,Structure-Based Features for Predicting the Quality of Articles in Wikipedia,2017,Baptiste de La Robertie; Y. Pitarch; O. Teste,Journal,N/A,17,0,"Success of Wikipedia is decidedly due to the free availability of high quality articles across many different expertise areas. If most of these resolute collaborations between authoritative users might constitute referenceable sources, Wikipedia is not sheltered from well-identified problems regarding articles quality, e.g., reputability of third-party sources and vandalism. Because of the huge number of articles and the intensive edit rate, it is not reasonable to even consider the manual evaluation of the content quality of each article. In this paper, we tackle the problem of modeling and predicting the quality of articles in collaborative platforms. We propose a quality model integrating both temporal and structural features captured from the implicit peer review process enabled by Wikipedia. A generic HITS-like framework is developed and able to capture both the quality of the content and the authority of the associated authors. Notably, a mutual reinforcement principle held between articles quality and author’s authority is exploited in order to take advantage of the collaborative graph generated by the users. Experiments conducted on a set of representative data from Wikipedia show the effectiveness of the computed indicators both in an unsupervised and supervised scenario.",,https://link.springer.com/content/pdf/10.1007/978-3-319-51049-1_6,https://link.springer.com/chapter/10.1007/978-3-319-51049-1_6
173,Google Scholar,Evaluating Article Quality and Editor Reputation in Wikipedia,2013,Yuqing Lu; Lei Zhang; Juan-Zi Li,Conference,"China Semantic Web Symposium, pp. 215-227",23,0,"We study a novel problem of quality and reputation evaluation for Wikipedia articles. We propose a difficult and interesting question: How to generate reasonable article quality score and editor reputation in a framework at the same time? In this paper, We propose a dual wing factor graph(DWFG) model, which utilizes the mutual reinforcement between articles and editors to generate article quality and editor reputation. To learn the proposed factor graph model, we further design an efficient algorithm. We conduct experiments to validate the effectiveness of the proposed model. By leveraging the belief propagation between articles and editors, our approach obtains significant improvement over several alternative methods(SVM, LR, PR, CRF). ",,https://link.springer.com/content/pdf/10.1007/978-3-642-54025-7_19,https://link.springer.com/chapter/10.1007/978-3-642-54025-7_19
197,"Google Scholar, Web of Science",Predicting Low-Quality Wikipedia Articles Using User’s Judgements,2015,Ning Zhang; Lingyun Ruan; Luo Si,Journal,N/A,8,0,"Wikipedia has become the most popular on-line encyclopedia. Millions of users rely on it to obtain desired knowledge and thus it becomes important and practical to model the quality of Wikipedia articles and to have inferior contents which bother readers or even mislead readers to be predicted. While identifying low-quality articles with manual efforts is a possible solution, it costs too much manpower and is too time-consuming. In this paper, we utilize article ratings from Wikipedia users for the first time to assess article quality. We define “low-quality” based on those ratings and design automatic methods to identify potential low-quality articles. More specifically, we formulate the problem as a set of binary classification problems and label articles according to whether they are “low-quality”. We compare two baseline algorithms and Logistic Regression algorithm, and the results indicate that it is promising to design effective and efficient automatic solutions for the task. We believe that our work is important for ensuring the quality of Wikipedia, as well as other knowledge markets. ",,https://link.springer.com/content/pdf/10.1007/978-3-319-05467-4_6,https://link.springer.com/chapter/10.1007/978-3-319-05467-4_6
199,"ACM, Google Scholar",An investigation of the relationship between the amount of extra-textual data and the quality of Wikipedia articles,2013,Marcelo Yuji Himoro; Raíza Hanada; Marco Cristo; M. G. Pimentel,Conference,"Brazilian Symposium on Multimedia and the Web, pp. 333-336",16,0,"Wikipedia, a web-based collaboratively maintained free encyclopedia, is emerging as one of the most important websites on the internet. However, its openness raises many concerns about the quality of the articles and how to assess it automatically. In the Portuguese-speaking Wikipedia, articles can be rated by bots and by the community. In this paper, we investigate the correlation between these ratings and the count of media items (namely images and sounds) through a series of experiments. Our results show that article ratings and the count of media items are correlated.",,https://dl.acm.org/doi/pdf/10.1145/2526188.2526218,https://dl.acm.org/doi/10.1145/2526188.2526218
262,ACM,Cultural diversity of quality of information on Wikipedias,2017,D. Jemielniak; Maciej Wilamowski,Journal,"Journal of the Association for Information Science and Technology, 68",52,26,"This article explores the relationship between linguistic culture and the preferred standards of presenting information based on article representation in major Wikipedias. Using primary research analysis of the number of images, references, internal links, external links, words, and characters, as well as their proportions in Good and Featured articles on the eight largest Wikipedias, we discover a high diversity of approaches and format preferences, correlating with culture. We demonstrate that high‐quality standards in information presentation are not globally shared and that in many aspects, the language culture's influence determines what is perceived to be proper, desirable, and exemplary for encyclopedic entries. As a result, we demonstrate that standards for encyclopedic knowledge are not globally agreed‐upon and “objective” but local and very subjective.",,https://crow.kozminski.edu.pl/papers/cultures%20of%20wikipedias.pdf,https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.23901
338,Web of Science,On the Feasibility of External Factual Support as Wikipedia's Quality Metric,2017,Carlos G. Velázquez; L. Cagnina; M. Errecalde,Journal,"Proces. del Leng. Natural, 58, pp. 93-100",20,5,"Developing metrics to estimate the information quality of Wikipedia articles is an interesting and important research area. In this article, we propose and analyse the feasibility, of a new quality metric based on the “external factual support” of an article. The rationale behind this metric is identified, a formal definition of the metric is presented and some implementation aspects are introduced. Preliminary results show the feasibility of our proposal and its potential to discriminate high quality versus low quality Wikipedia’s articles.",,http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/5417/3181,http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/5417
359,Web of Science,Quality of Wikipedia Articles: Analyzing Features and Building a Ground Truth for Supervised Classification,2019,Elias Bassani; Marco Viviani,Conference,"International Conference on Knowledge Discovery and Information Retrieval, pp. 338-346",35,3,"Wikipedia is nowadays one of the biggest online resources on which users rely as a source of information. The amount of collaboratively generated content that is sent to the online encyclopedia every day can let to the possible creation of low-quality articles (and, consequently, misinformation) if not properly monitored and revised. For this reason, in this paper, the problem of automatically assessing the quality of Wikipedia articles is considered. In particular, the focus is (i) on the analysis of groups of hand-crafted features that can be employed by supervised machine learning techniques to classify Wikipedia articles on qualitative bases, and (ii) on the analysis of some issues behind the construction of a suitable ground truth. Evaluations are performed, on the analyzed features and on a specifically built labeled dataset, by implementing different supervised classifiers based on distinct machine learning algorithms, which produced promising results.",,https://pdfs.semanticscholar.org/f118/37c304132974ec60f0fa98a2e8ecf161a313.pdf,https://boa.unimib.it/handle/10281/249678
